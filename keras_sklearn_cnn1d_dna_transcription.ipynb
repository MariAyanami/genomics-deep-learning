{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/charlesreid1/deep-learning-genomics/blob/master/keras_sklearn_cnn1d_dna_transcription.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JHAuCkB-Dyvx"
   },
   "source": [
    "# Keras and Sklearn for Deep Learning Genomics\n",
    "\n",
    "This notebook continues with the example from a prior notebook, namely, the problem of predicting transcription factor binding sites in DNA. This type of neural network operates on 1D sequence data (DNA nucleotides), so we build a 1D convolutional neural network to perform classification of DNA (is this string of nucleotides a transcription factor binding site or not).\n",
    "\n",
    "We construct several models in this notebook:\n",
    "\n",
    "* 1D CNN that does not incorporate chromatin data\n",
    "* 1D CNN that incorporates (un-transformed) chromatin data and uses sample weights\n",
    "* 1D CNN that incorporates (un-transformed) chromatin data and uses class weights\n",
    "\n",
    "We then perform manual cross-validation on each model and assemble statistics to assess the cross-validation results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bAl5v_fEEz8Y"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "62b9p_xalIIH",
    "outputId": "730e6bac-4c23-4e7c-c175-bd97f6956a56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 132,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4gsmsa71Dv1k"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1fhj_7ZaEPij"
   },
   "outputs": [],
   "source": [
    "# sklearn\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VN-bDjOlEQDB"
   },
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Embedding, Dense, Dropout, Input, Concatenate\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "from keras.layers import LeakyReLU\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aHkVmJYCEZfT"
   },
   "outputs": [],
   "source": [
    "seed = 1729\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZeBqpoaQcPvk"
   },
   "source": [
    "## Define Useful Keras Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UpthrvB3cST3"
   },
   "outputs": [],
   "source": [
    "# via https://github.com/keras-team/keras/issues/6507#issuecomment-322857357\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    # Calculate the precision\n",
    "    # clip ensures we're between 0 and 1\n",
    "    # round ensures we're either 0 or 1\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    # Calculate the recall\n",
    "    # clip ensures we're between 0 and 1\n",
    "    # round ensures we're either 0 or 1\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def fvalue(y_true, y_pred):\n",
    "    # Calculate the F-value\n",
    "    # If there are no true positives, fix the F score at 0 like sklearn.\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0\n",
    "    p = precision(y_true,y_pred)\n",
    "    r = recall(y_true,y_pred)\n",
    "    fvalue = (2 * p * r)/(p + r + K.epsilon())\n",
    "    return fvalue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yf8K8vRzEx3q"
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nxrwVCIBEsNJ",
    "outputId": "72124115-6bb6-4490-ccda-3b6c214adff0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'DeepLearningLifeSciences' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/deepchem/DeepLearningLifeSciences.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sEUJnDsbEtQa"
   },
   "outputs": [],
   "source": [
    "!ln -fs DeepLearningLifeSciences/Chapter06/{test*,train*,valid*} ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KPileDhWZyu5"
   },
   "outputs": [],
   "source": [
    "!ln -fs DeepLearningLifeSciences/Chapter06/chromatin.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y4svZCHZZ5Wn"
   },
   "source": [
    "In contrast to the prior example, which uses the already-provided splits of training, testing, and validation, we will load all of the data all at once into a single X and y pair and use sklearn to split the data into testing and training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "nSLjlrPBSiP_",
    "outputId": "18c1f1a7-8ff9-44cb-8ae7-bde939483e09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of all data:\n",
      "\n",
      "X shape:\n",
      "(345271, 101, 4)\n",
      "chromatin shape:\n",
      "(345271,)\n",
      "y shape:\n",
      "(345271, 1)\n",
      "w shape:\n",
      "(345271, 1)\n"
     ]
    }
   ],
   "source": [
    "def load_all_data():\n",
    "    \n",
    "    # load chromatin accessibility data\n",
    "    accessibility = {}\n",
    "    for line in open('chromatin.txt','r'):\n",
    "        fields = line.split()\n",
    "        accessibility[fields[0]] = float(fields[1])\n",
    "    \n",
    "    # load training, validation, and testing sets\n",
    "    for i,label in enumerate(['train','valid','test']):\n",
    "        datadir = \"%s_dataset\"%(label)\n",
    "        base_filename = \"shard-0-%s.joblib\"\n",
    "        X_filename = os.path.join(datadir,base_filename%(\"X\"))\n",
    "        y_filename = os.path.join(datadir,base_filename%(\"y\"))\n",
    "        w_filename = os.path.join(datadir,base_filename%(\"w\"))\n",
    "        ids_filename = os.path.join(datadir,base_filename%(\"ids\"))\n",
    "        \n",
    "        this_X = joblib.load(X_filename)\n",
    "        this_y = joblib.load(y_filename)\n",
    "        this_w = joblib.load(w_filename)\n",
    "        this_ids = joblib.load(ids_filename)\n",
    "        this_chromatin = np.array([accessibility[k] for k in this_ids])\n",
    "        \n",
    "        # add X and chromatin data\n",
    "        if i>0:\n",
    "            X = np.concatenate([X,this_X])\n",
    "            chromatin = np.concatenate([chromatin,this_chromatin])\n",
    "            y = np.concatenate([y,this_y])\n",
    "            w = np.concatenate([w,this_w])\n",
    "            ids = np.concatenate([ids,this_ids])\n",
    "        else:\n",
    "            X = this_X\n",
    "            chromatin = this_chromatin\n",
    "            y = this_y\n",
    "            w = this_w\n",
    "            ids = this_ids\n",
    "        \n",
    "    return [X,chromatin], y, w, ids\n",
    "\n",
    "[X,chromatin], y, w, ids = load_all_data()\n",
    "\n",
    "print(\"Shape of all data:\\n\")\n",
    "\n",
    "print(\"X shape:\")\n",
    "print(np.shape(X))\n",
    "\n",
    "print(\"chromatin shape:\")\n",
    "print(np.shape(chromatin))\n",
    "\n",
    "print(\"y shape:\")\n",
    "print(np.shape(y))\n",
    "\n",
    "print(\"w shape:\")\n",
    "print(np.shape(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0iNXUOqHUSXN"
   },
   "source": [
    "## Stratified K-Fold Validation\n",
    "\n",
    "Now that we've loaded every data point into a single giant input list, we use scikit-learn to cut the data into training, testing, and validation parts.\n",
    "\n",
    "We use the \"normal\" kernel initializer, which initializes perceptron weights using normally-distributed random numbers.\n",
    "\n",
    "We create two functions below:\n",
    "\n",
    "* `create_baseline()` - creates a keras model that does not incorporate chromatin accessibility data\n",
    "* `create_chromatin()` - creates a keras model that utilizes chromatin accessibility data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ESwAIdQmEoZg"
   },
   "outputs": [],
   "source": [
    "def create_baseline():\n",
    "    \"\"\"Create and return a baseline 1D convolutional neural net model.\n",
    "    This model does not incorporate chromatin accessibility data.\n",
    "    \"\"\"\n",
    "    # DNA sequence alphabet size\n",
    "    n_features = 4\n",
    "    seq_length = 101\n",
    "    convolution_window = 10\n",
    "    n_filters = 16\n",
    "    \n",
    "    # construct model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Layer 1\n",
    "    model.add(Conv1D(n_filters, convolution_window,\n",
    "                     activation='relu',\n",
    "                     padding='same',\n",
    "                     kernel_initializer='normal',\n",
    "                     input_shape=(seq_length, n_features)))\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    # Layer 2\n",
    "    model.add(Conv1D(n_filters, convolution_window,\n",
    "                     activation='relu', \n",
    "                     padding='same',\n",
    "                     kernel_initializer='normal'))\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    # Layer 3\n",
    "    model.add(Conv1D(n_filters, convolution_window,\n",
    "                     activation='relu', \n",
    "                     padding='same',\n",
    "                     kernel_initializer='normal'))\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    # Flatten\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Shrink to 1 neuron for 1 class (binary) classification\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  sample_weight_mode=None,\n",
    "                  metrics=['accuracy',\n",
    "                           precision,\n",
    "                           recall,\n",
    "                           fvalue])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8eI1zuvCaybP"
   },
   "outputs": [],
   "source": [
    "def create_chromatin():\n",
    "    \"\"\"Create and return a 1D convolutional neural net model.\n",
    "    This model incorporates chromatin accessibility data.\n",
    "    \"\"\"\n",
    "    # DNA sequence alphabet size\n",
    "    n_features = 4\n",
    "    seq_length = 101\n",
    "    convolution_window = 10\n",
    "    n_filters = 16\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Sequence branch of network\n",
    "    # (1D DNA sequence)\n",
    "    \n",
    "    # Input\n",
    "    seq_in = Input(shape=(seq_length,n_features))\n",
    "    \n",
    "    # Fencepost pattern\n",
    "    seq = seq_in\n",
    "    \n",
    "    # Convolutional layers\n",
    "    for i in range(3):\n",
    "        seq = Conv1D(n_filters, convolution_window,\n",
    "                    activation='relu', padding='same')(seq)\n",
    "        seq = Dropout(0.5)(seq)\n",
    "    \n",
    "    # Flatten to 1D\n",
    "    seq = Flatten()(seq)\n",
    "    \n",
    "    # Assemble the sequential branch of network\n",
    "    seq = keras.Model(inputs=seq_in, outputs=seq)\n",
    "    \n",
    "    # ---------------------------\n",
    "    # Chromatin branch of network\n",
    "    \n",
    "    # Input\n",
    "    chrom_input = 