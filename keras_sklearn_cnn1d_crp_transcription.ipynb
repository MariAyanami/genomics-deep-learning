{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of keras-sklearn_cnn1d_crp_transcription.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/charlesreid1/deep-learning-genomics/blob/master/keras_sklearn_cnn1d_crp_transcription.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JHAuCkB-Dyvx"
      },
      "source": [
        "# Keras and Sklearn for Deep Learning Genomics\n",
        "\n",
        "## Using Convolutional Neural Nets to Predict CRP Transcription Factor Binding Sites\n",
        "\n",
        "This notebook continues with the example from a prior notebook, namely, the problem of predicting transcription factor binding sites in DNA. This type of neural network operates on 1D sequence data (DNA nucleotides), so we build a 1D convolutional neural network to perform classification of DNA (is this string of nucleotides a transcription factor binding site or not).\n",
        "\n",
        "We construct a 1D CNN model in this notebook, then perform manual cross-validation on each model and assemble statistics to assess the cross-validation results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bAl5v_fEEz8Y"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "62b9p_xalIIH",
        "outputId": "1bfd68fb-c51b-4ce0-8f95-5d26a2ce99e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4gsmsa71Dv1k",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas\n",
        "import joblib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDKOca34psQB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy import interp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elpTR8POpsQT",
        "colab_type": "code",
        "outputId": "c6d7856d-df3e-4f03-80e0-14222bb23b05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "!pip install screed"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting screed\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/7a/b5f16a9861ac497b346b2f5205e8dc35103eeba1e6fdffa114c47e0b35ba/screed-1.0.tar.gz (130kB)\n",
            "\r\u001b[K     |██▌                             | 10kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 71kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 81kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from screed) (0.98)\n",
            "Building wheels for collected packages: screed\n",
            "  Building wheel for screed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/92/73/33877695d382ad5f342aaa8c8835d83895766b39bf6989f350\n",
            "Successfully built screed\n",
            "Installing collected packages: screed\n",
            "Successfully installed screed-1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1fhj_7ZaEPij",
        "colab": {}
      },
      "source": [
        "# sklearn\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VN-bDjOlEQDB",
        "outputId": "37c69bf3-90bc-4986-c408-f656c63c12cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Flatten, Embedding, Dense, Dropout, Input, Concatenate\n",
        "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
        "from keras.layers import LeakyReLU\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aHkVmJYCEZfT",
        "colab": {}
      },
      "source": [
        "seed = 1729\n",
        "numpy.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZeBqpoaQcPvk"
      },
      "source": [
        "## Define Useful Keras Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UpthrvB3cST3",
        "colab": {}
      },
      "source": [
        "# via https://github.com/keras-team/keras/issues/6507#issuecomment-322857357\n",
        "\n",
        "import keras.backend as K\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    # Calculate the precision\n",
        "    # clip ensures we're between 0 and 1\n",
        "    # round ensures we're either 0 or 1\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "    # Calculate the recall\n",
        "    # clip ensures we're between 0 and 1\n",
        "    # round ensures we're either 0 or 1\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def fvalue(y_true, y_pred):\n",
        "    # Calculate the F-value\n",
        "    # If there are no true positives, fix the F score at 0 like sklearn.\n",
        "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
        "        return 0\n",
        "    p = precision(y_true,y_pred)\n",
        "    r = recall(y_true,y_pred)\n",
        "    fvalue = (2 * p * r)/(p + r + K.epsilon())\n",
        "    return fvalue\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Yf8K8vRzEx3q"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nxrwVCIBEsNJ",
        "outputId": "047e7e10-7de4-4c9d-f41e-366565b9ca06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "# grab binding sites from http://arep.med.harvard.edu/ecoli_matrices/dat/crp.dat\n",
        "!wget http://arep.med.harvard.edu/ecoli_matrices/dat/crp.dat"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-01 17:49:41--  http://arep.med.harvard.edu/ecoli_matrices/dat/crp.dat\n",
            "Resolving arep.med.harvard.edu (arep.med.harvard.edu)... 134.174.150.51\n",
            "Connecting to arep.med.harvard.edu (arep.med.harvard.edu)|134.174.150.51|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1966 (1.9K) [text/plain]\n",
            "Saving to: ‘crp.dat’\n",
            "\n",
            "\rcrp.dat               0%[                    ]       0  --.-KB/s               \rcrp.dat             100%[===================>]   1.92K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-07-01 17:49:41 (412 MB/s) - ‘crp.dat’ saved [1966/1966]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sEUJnDsbEtQa",
        "outputId": "8f845034-45e9-469e-e928-44ae726327d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# grab ecoli k12 genome\n",
        "!curl ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/003/627/195/GCF_003627195.1_ASM362719v1/GCF_003627195.1_ASM362719v1_genomic.fna.gz -o ecoli-k12.fna.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1347k  100 1347k    0     0  1935k      0 --:--:-- --:--:-- --:--:-- 1932k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KPileDhWZyu5",
        "colab": {}
      },
      "source": [
        "import screed\n",
        "ecoli_genome = list(screed.open('ecoli-k12.fna.gz'))[0].sequence\n",
        "crp_sites = list(screed.open('crp.dat'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_jzasLmpsSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ecoli_genome = ecoli_genome.upper()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqxVC-UZpsSn",
        "colab_type": "text"
      },
      "source": [
        "## Explore Dataset\n",
        "\n",
        "Below we explore some details of the CRP transcription factor binding site data set that we'll use to train and test the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-WrQvFQpsSo",
        "colab_type": "code",
        "outputId": "e2361db0-ae77-4936-ed2e-c78edbb134b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"E. coli genome size: {:,}\".format(len(ecoli_genome)))\n",
        "print(\"Number of CRP binding sites: {:,}\".format(len(crp_sites)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E. coli genome size: 4,639,694\n",
            "Number of CRP binding sites: 49\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIkR_DMzpsSz",
        "colab_type": "code",
        "outputId": "77563914-0495-4846-9c13-82a7ea358a27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(type(ecoli_genome))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'str'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLVLPkgvpsS7",
        "colab_type": "text"
      },
      "source": [
        "The E. coli genome is a ~4 MB string and we have 49 known binding sites. We have only \"known positive\" binding sites; we have no \"known negative\" binding sites. In other words, we cannot say that a particular sequence of DNA is _definitely not_ a binding site, we can only say that it is _probably not_ a binding site."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFKifmbUpsS9",
        "colab_type": "code",
        "outputId": "4982c42f-3457-4728-f71a-91656c2119a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "crp_sites[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'aldB -18->4', 'sequence': 'attcgtgatagctgtcgtaaag', 'description': ''},\n",
              " {'name': 'ansB 103->125', 'sequence': 'ttttgttacctgcctctaactt', 'description': ''},\n",
              " {'name': 'araB1 109->131', 'sequence': 'aagtgtgacgccgtgcaaataa', 'description': ''},\n",
              " {'name': 'araB2 147->169', 'sequence': 'tgccgtgattatagacactttt', 'description': ''},\n",
              " {'name': 'cdd 1 107->129', 'sequence': 'atttgcgatgcgtcgcgcattt', 'description': ''}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEmv-S5MpsTC",
        "colab_type": "text"
      },
      "source": [
        "### Generating Positive Examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JjrMKCKpsTE",
        "colab_type": "code",
        "outputId": "299f3577-5a91-4379-8286-de9d4551c70b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "crp_kmers = []\n",
        "for site in crp_sites:\n",
        "    crp_kmers.append(site['sequence'].upper())\n",
        "\n",
        "len_crp = len(crp_kmers[0]) # all CRP sites are the same length\n",
        "print('Size of CRP binding site:', len_crp)\n",
        "print('Number of known good CRP binding sites:', len(crp_kmers))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of CRP binding site: 22\n",
            "Number of known good CRP binding sites: 49\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySvq0pikpsTI",
        "colab_type": "text"
      },
      "source": [
        "The CRP binding sites are all sequences of 22 nucleotides. We have 49 positive examples. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Csx1G-BxpsTL",
        "colab_type": "text"
      },
      "source": [
        "### Kmer Orientations and Reverse Complements\n",
        "\n",
        "Normally we would want to think about whether the orientation of the kmer (forward or backward from what is given in the data set we downloaded) matters. However, the CRP t.f. binding sites are all palindromes, so orientation should not matter.\n",
        "\n",
        "However, we _can_ generate additional positive examples by finding the reverse complement of each CRP t.f. binding site kmer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pShBOpJbpsTN",
        "colab_type": "code",
        "outputId": "8d336449-e293-432b-a1ba-a93f873d977e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "TRANSLATION = {\"A\": \"T\", \"C\": \"G\", \"G\": \"C\", \"T\": \"A\"}\n",
        "\n",
        "def revc(pattern):\n",
        "    return \"\".join(TRANSLATION[c] for c in reversed(pattern))\n",
        "\n",
        "for k in range(len(crp_kmers)):\n",
        "    crp_kmers.append(revc(crp_kmers[k]))\n",
        "\n",
        "print('Number of known good CRP binding sites (with rev. complements):', len(crp_kmers))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of known good CRP binding sites (with rev. complements): 98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pan4pm0kpsTU",
        "colab_type": "text"
      },
      "source": [
        "### Generating Negative Examples\n",
        "\n",
        "Next, we can generate negative examples (ignoring the fact mentioned above, that we can't say with certainty that these are negative examples) by generating 22-mers from the E. coli genome.\n",
        "\n",
        "We will generate a **slim** and a **full** data set. The slim data set will use the first 100,000 22-mers. The full data set will use the entire E. coli genome."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Pi8tsAspsTU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "do_slim = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OwI9tXDpsTb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if do_slim:\n",
        "    \n",
        "    N_NEGATIVES=int(1e5) # 100,000 negative binding sites\n",
        "\n",
        "    notcrp_kmers_slim = []\n",
        "    for n in range(N_NEGATIVES):\n",
        "        kmer = ecoli_genome[n:n + len_crp]\n",
        "        if kmer not in crp_kmers:\n",
        "            notcrp_kmers_slim.append(kmer)\n",
        "\n",
        "    print('Gathered {:,} negative binding sites'.format(len(notcrp_kmers_slim)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urGHnJxPpsTi",
        "colab_type": "code",
        "outputId": "68eaa094-2161-41d0-d004-0dbf22ab8230",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if not do_slim:\n",
        "    \n",
        "    notcrp_kmers_full = []\n",
        "    overlap = len(ecoli_genome)-len_crp+1\n",
        "    for n in range(overlap):\n",
        "        kmer = ecoli_genome[n:n + len_crp]\n",
        "        if kmer not in crp_kmers:\n",
        "            notcrp_kmers_full.append(kmer)\n",
        "\n",
        "    print('Gathered {:,} negative binding sites'.format(len(notcrp_kmers_full)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gathered 4,639,626 negative binding sites\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTlkMMxEpsTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if do_slim:\n",
        "    notcrp_kmers = notcrp_kmers_slim\n",
        "else:\n",
        "    notcrp_kmers = notcrp_kmers_full"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w224nBATpsTt",
        "colab_type": "text"
      },
      "source": [
        "A brief comment on dealing with uncertainty in the positive and negative cases: this is a source of uncertainty inherent to the system being modeled - it is not something that can be overcome with a better model. Training a better model requires more information, in the form of probabilities - the probability that a kmer is a negative example. In the absence of additional information, such as an estimate of the number of missing positive examples, we have to make assumptions.\n",
        "\n",
        "Ultimately the output of the model is a probabilistic guess about which class a given kmer belongs in - positive (yes, this is a CRP t.f. site) or negative (no, this is not a CRP t.f. site). We are looking for places where we can't quite rule something out based on the data we have, and the classification system is **more sensitive** to the training data set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBZYkihqpsTu",
        "colab_type": "text"
      },
      "source": [
        "### One-Hot Encoding of Dataset\n",
        "\n",
        "To use the kmers that compose our positive and negative exmaples, we need to one-hot encode the DNA sequences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4UH7ytupsTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# do janky one-hot encoding\n",
        "oh = {}\n",
        "oh['A'] = [1, 0, 0, 0]\n",
        "oh['C'] = [0, 1, 0, 0]\n",
        "oh['G'] = [0, 0, 1, 0]\n",
        "oh['T'] = [0, 0, 0, 1]\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "# First encode the positive examples\n",
        "\n",
        "for site in crp_kmers:\n",
        "    encoded_site = []\n",
        "    for c in site:\n",
        "        encoded_site.append(oh[c])\n",
        "    \n",
        "    X.append(encoded_site)\n",
        "    y.append([1])\n",
        "        \n",
        "\n",
        "for site in notcrp_kmers:\n",
        "    encoded_site = []\n",
        "    for c in site:\n",
        "        encoded_site.append(oh[c])\n",
        "    \n",
        "    X.append(encoded_site)\n",
        "    y.append([0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfuNWJr3psT2",
        "colab_type": "code",
        "outputId": "cb762d77-b760-4985-f0fd-9e1edbaae67a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Setting the dtype can save us some space\n",
        "X = np.array(X, dtype=np.int8)\n",
        "y = np.array(y, dtype=np.int8)\n",
        "\n",
        "print(np.shape(X))\n",
        "print(np.shape(y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4639724, 22, 4)\n",
            "(4639724, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utr6E2rVpsT7",
        "colab_type": "code",
        "outputId": "49d4a401-884b-428b-d053-f2a7e03d0bb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(type(X[0][0][0]))\n",
        "print(type(y[0][0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.int8'>\n",
            "<class 'numpy.int8'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OO3CY13psT_",
        "colab_type": "code",
        "outputId": "ae178a0a-517c-4c80-9a0a-1acac3589785",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pos = sum(y==1)\n",
        "neg = sum(y==0)\n",
        "print(\"Percent of examples that are positive: %0.4f%%\"%(100*pos/(pos+neg)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percent of examples that are positive: 0.0021%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBKhyxu3psUE",
        "colab_type": "text"
      },
      "source": [
        "### Computing Class and Sample Weights\n",
        "\n",
        "Because we are dealing with a highly imbalanced data set, we should use class weights to weight the positive examples more heavily, so the neural network doesn't learn to simply make negative preditions all the time.\n",
        "\n",
        "Class weights are easier to deal with and apply the same weight to all instances of a given class.\n",
        "\n",
        "Sample weights assign a different weight to every piece of input data. These are more expensive and consume space, but some scikit-learn functions can only accept sample weights, not class weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yblu-kt4psUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute class weights:\n",
        "classes = np.unique(y)\n",
        "labels = np.squeeze(y)\n",
        "weights = compute_class_weight('balanced',classes,labels)\n",
        "\n",
        "class_weights = {}\n",
        "for k,wt in zip(classes,weights):\n",
        "    class_weights[k] = wt\n",
        "\n",
        "sample_weights = []\n",
        "for yi in y:\n",
        "    k = yi[0]\n",
        "    sample_weights.append([class_weights[k]])\n",
        "\n",
        "sample_weights = np.array(sample_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXkhyviepsUH",
        "colab_type": "text"
      },
      "source": [
        "## Performing Stratified K-Fold Validation\n",
        "\n",
        "Now we have all input and output data for training the neural network model in the variables X and y. We can use scikit-learn to create testing-training splits that maintain a balance between positive and negative examples. \n",
        "\n",
        "* First, we write a function to create a model (independent of input/output data).\n",
        "* Second, we perform k-fold validation, creating a new model each time. We create new stratified, shuffled testing-training splits from X and y each time we do a new cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYhqXgV-psUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_baseline():\n",
        "    \"\"\"Create and return a baseline 1D convolutional neural net model.\n",
        "    \"\"\"\n",
        "    # DNA sequence alphabet size\n",
        "    n_features = 4\n",
        "    seq_length = len_crp\n",
        "    convolution_window = 25\n",
        "    n_filters = 16\n",
        "    \n",
        "    # construct model\n",
        "    model = Sequential()\n",
        "    \n",
        "    # Layer 1\n",
        "    model.add(Conv1D(n_filters, convolution_window,\n",
        "                     activation='relu',\n",
        "                     padding='same',\n",
        "                     kernel_initializer='normal',\n",
        "                     input_shape=(seq_length, n_features)))\n",
        "    \n",
        "    model.add(Dropout(0.5))\n",
        "    \n",
        "    # Layer 2\n",
        "    model.add(Conv1D(n_filters, convolution_window,\n",
        "                     activation='relu', \n",
        "                     padding='same',\n",
        "                     kernel_initializer='normal'))\n",
        "    \n",
        "    model.add(Dropout(0.5))\n",
        "    \n",
        "    # Layer 3\n",
        "    model.add(Conv1D(n_filters, convolution_window,\n",
        "                     activation='relu', \n",
        "                     padding='same',\n",
        "                     kernel_initializer='normal'))\n",
        "    \n",
        "    model.add(Dropout(0.5))\n",
        "    \n",
        "    # Flatten\n",
        "    model.add(Flatten())\n",
        "    \n",
        "    # Shrink to 1 neuron for 1 class (binary) classification\n",
        "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
        "    \n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "      